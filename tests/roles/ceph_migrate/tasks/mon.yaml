# Get a client using -v /home/tripleo-admin/ceph_config:/etc/ceph:z as input
- name: Get ceph_cli
  include_tasks: ceph_cli.yaml
  vars:
    ceph_config_home: "{{ ceph_config_tmp_client_home }}"
    ceph_fsid: "{{ mon_dump.fsid }}"
    ceph_cluster: ceph

- name: Migrate mon
  when: debug | default(true)
  ansible.builtin.debug:
    msg: "Migrate mon: {{ cur_mon.split('.')[0] }} to node: {{ target_node }}"

# We add labels in advance to the target node to make sure we are able to
# deploy a tmp mon that will be replaced with the right one (on the desired
# network). By adding an additional mon at this stage we can ensure we always
# have quorum and at least 3 active mons while migrating the src daemon to the
# target node.
- name: MON - Setup Mon/Mgr label to the target node
  ansible.builtin.include_tasks: labels.yaml
  vars:
    nodes:
      - "{{ target_node }}"
    action: "add"
    labels:
      - "mon"
      - "mgr"
      - "_admin"

- name: MON - check mons quorum
  become: true
  ansible.builtin.command: "{{ ceph_cli }} -s -f json"
  register: monmap
  retries: 20
  delay: 2
  # >= is related to the fact that the current monmap might still have
  # references to the old mon daemon coming from the drained node
  until: (monmap.stdout | from_json | community.general.json_query('monmap.num_mons') | int) >= ((decomm_nodes |default([]) | length | int) | default(3))
  loop_control:
    label: "check mons quorum"

- name: Backup data for client purposes
  delegate_to: "{{ cur_mon.split('.')[0] }}.ctlplane"
  block:
    - name: Ensure backup directory exists
      ansible.builtin.file:
        path: "{{ ceph_config_tmp_client_home }}"
        state: directory
    - name: Check file in the src directory
      ansible.builtin.find:
        paths: /etc/ceph
        patterns: "*"
      register: dir_ceph_files
    - name: Backup ceph client data
      when: dir_ceph_files.files | length > 0
      become: true
      ansible.builtin.copy:
        remote_src: true
        src: "/etc/ceph/{{ item }}"
        dest: "{{ ceph_config_tmp_client_home }}"
      loop:
        - ceph.conf
        - ceph.client.admin.keyring

# Before draining the current node, migrate the active mgr on a different
# _admin host
- name: Migrate Ceph mgr from the current node if required
  block:
    - name: Get the current mgrmap dump
      become: true
      ansible.builtin.command:
        "{{ ceph_cli }} mgr dump -f json"
      register: mgr

    - name: Load mgr data
      ansible.builtin.set_fact:
        mgr: "{{ mgr.stdout | from_json }}"

    - name: Print active mgr
      when: debug | default(true)
      ansible.builtin.debug:
        msg: "Active mgr: {{ mgr.active_name }}"

    - name: Fail mgr if active in the current node
      become: true
      ansible.builtin.command:
        "{{ ceph_cli }} mgr fail {{ mgr.active_name }}"
      when:
        - mgr.active_name | length > 0
        - mgr.active_name | regex_search(cur_mon)

# Drain and rm the cur_mon from the Ceph cluster
- name: MON - Drain and rm --force the cur_mon host
  #when: cur_mon in decomm_nodes
  ansible.builtin.include_tasks: drain.yaml
  vars:
    host: "{{ cur_mon }}"
  tags:
    - ceph_drain

# The node should be empty at this point, let's remove it from the Ceph
# cluster
- name: MON - rm the cur_mon host from the Ceph cluster
  #when: cur_mon in decomm_nodes
  become: true
  ansible.builtin.command:
    "{{ ceph_cli }} orch host rm {{ cur_mon }} --force"
  # let's ignore this for now (for idempotency purposes)
  ignore_errors: true
  tags:
    - ceph_drain

- name: MON - Get current mon IP address
  #when: cur_mon in decomm_nodes
  ansible.builtin.set_fact:
    mon_ipaddr: "{{ mon_ip | split(':') | first | ansible.utils.ipaddr }}"
  vars:
    mon_ip: |-
      {% for mon in mon_dump.mons %}
      {%   if mon.name == cur_mon.split('.')[0] %}
      {{ mon.addr }}
      {%   endif %}
      {% endfor %}

- name: MON - Move the mon IP Address from {{ cur_mon }} to {{ target_node }}
  become: true
  # if no mon addr, this variable is False and the whole block is skipped
  # because there's no network related action that should be performed
  when:
    #- cur_mon in decomm_nodes
    - mon_ipaddr | default('')
  block:
    - name: MON - Get current mon IP address
      when: debug | default(true)
      ansible.builtin.debug:
        msg: "{{ mon_ipaddr }}"

    - name: MON - Patch os-net-config config and REMOVE the current mon IP address
      delegate_to: "{{ cur_mon.split('.')[0] }}.ctlplane"
      lineinfile:
        path: "{{ os_net_conf_path }}"
        state: absent
        regexp: '{{ mon_ipaddr }}/24'
        backup: yes

    - name: MON - Refresh os-net-config
      delegate_to: "{{ cur_mon.split('.')[0] }}.ctlplane"
      ansible.builtin.shell:
        "os-net-config -c {{ os_net_conf_path }}"

    - name: MON - Patch os-net-config config and add the mon IP
      delegate_to: "{{ target_node.split('.')[0] }}.ctlplane"
      lineinfile:
        dest: "{{ os_net_conf_path }}"
        insertafter: "{{ ceph_storage_net_prefix }}"
        line: "  - ip_netmask: {{ mon_ipaddr }}/24"
        backup: yes

    - name: MON - Refresh os-net-config
      delegate_to: "{{ target_node.split('.')[0] }}.ctlplane"
      ansible.builtin.command:
        "os-net-config -c {{ os_net_conf_path }}"

    - name: MON - ping ip address to see if is reachable on the target node
      ansible.builtin.command:
        "ping -W1 -c 3 {{ mon_ipaddr }}"
      delegate_to: "{{ target_node.split('.')[0] }}.ctlplane"
      register: ping_target_ip

    - name: MON - Fail if the IP address is not active in the target node
      when: ping_target_ip.rc != 0
      fail:
        msg: "Can't reach the mon IP on the target node"

- name: Redeploy MON
  block:
    # when a label is added, if we're not fast enough, a mon is automatically
    # added on the storage network. However, in case the node has multiple ip
    # addresses, it might happen that the mon is deployed using the right IP.
    # For this reason we need to redeploy it by rm + add (as redeploy does not
    # accept an IP as input
    - name: MON - wait for mon
      become: true
      ansible.builtin.command: "{{ ceph_cli }} mon stat -f json"
      register: monstat
      retries: 20
      delay: 3
      until: "'{{ target_node.split('.')[0] }}' in monstat.stdout | from_json | community.general.json_query('quorum[*].name') | default([]) | list"
      loop_control:
        label: "MON - wait for mon"

    - name: MON - Delete the running mon
      become: true
      ansible.builtin.command:
        "{{ ceph_cli }} orch daemon rm mon.{{ target_node.split('.')[0] }} --force"
      ignore_errors: true

    - name: MON - Redeploy mon on {{ target_node }}
      become: true
      ansible.builtin.command:
        "{{ ceph_cli }} orch daemon add mon {{ target_node.split('.')[0] }}:{{ mon_ipaddr }}"

- name: MON - check mons quorum
  become: true
  ansible.builtin.command: "{{ ceph_cli }} -s -f json"
  register: monmap
  retries: 20
  delay: 2
  # >= is related to the fact that the current monmap might still have
  # references to the old mon daemon coming from the drained node
  until: (monmap.stdout | from_json | community.general.json_query('monmap.num_mons') | int) >= ((decomm_nodes |default([]) | length | int) | default(3))
  loop_control:
    label: "check mons quorum"

# Post actions: refresh mgr data, reconfigure osds
- name: MON - refresh cephadm info - fail ceph mgr and refresh osd config
  become: true
  block:
    - name: force-fail ceph mgr
      ansible.builtin.command: "{{ ceph_cli }} mgr fail"
    - name: reconfig osds
      ansible.builtin.command: "{{ ceph_cli }} orch reconfig osd.default_drive_group "

# Wait for the redeploy to finish before moving to the next stage
- ansible.builtin.include_tasks: wait_daemons.yaml
  vars:
    daemon: mon
    daemon_id: "{{ target_node.split('.')[0] }}"
