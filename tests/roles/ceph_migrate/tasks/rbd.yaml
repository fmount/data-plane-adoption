# The problem might be having a different size in the number of controller
# nodes (that should be decommissioned, and the number of target nodes: we
# need to establish rules and block the process if it's not possible to
# complete the migration (either because of cardinality of just because we
# don't have enough nodes).

- name: Setup a Ceph client to the first node
  block:
    - ansible.builtin.include_tasks: network.yaml
      vars:
        #cur_mon: "{{ decomm_nodes | list | sort | first }}"
        cur_mon: controller-0
      tags:
        - ceph_network

# Extend mgr deployment to help with failover
- name: MGR - Migrate RBD node
  ansible.builtin.include_tasks: mgr.yaml

# we need to serially migrate mons, so we loop over the nodes and run the
# procedure provided by mon.yaml
- name: MON - Migrate RBD node
  ansible.builtin.include_tasks: mon.yaml
  vars:
    cur_mon: controller-0 #.redhat.local
    target_node: cephstorage-0 #.redhat.local
    #cur_mon: "{{ node.0 }}"
    #target_node: "{{ node.1 }}"
  # This condition might be a different one
  #loop: "{{ decomm_nodes|zip(hostmap.keys() | difference(decomm_nodes) | sort) | list }}"
  #loop_control:
  #  loop_var: node

